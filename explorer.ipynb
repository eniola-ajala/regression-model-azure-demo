{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Explore the data\n",
    "\n",
    "https://insights.stackoverflow.com/survey\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Download the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "# From https://insights.stackoverflow.com/survey\n",
    "url = 'https://info.stackoverflowsolutions.com/rs/719-EMH-566/images/stack-overflow-developer-survey-2022.zip'\n",
    "filehandle, _ = urllib.request.urlretrieve(url)\n",
    "zip_file_object = zipfile.ZipFile(filehandle, 'r')\n",
    "file = zip_file_object.open('survey_results_public.csv')\n",
    "content = file.read()\n",
    "content[0:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Load the CSV into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "\n",
    "survey_data = pd.read_csv('data/survey_results_public.csv')\n",
    "survey_data.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ConvertedCompYearly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>34673.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>82283.28449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>65903.17731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>35904.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>65820.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>111360.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>400000.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ConvertedCompYearly\n",
       "count          34673.00000\n",
       "mean           82283.28449\n",
       "std            65903.17731\n",
       "min                1.00000\n",
       "25%            35904.00000\n",
       "50%            65820.00000\n",
       "75%           111360.00000\n",
       "max           400000.00000"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows with no data\n",
    "survey_data = survey_data.dropna(subset = [\"ConvertedCompYearly\"])\n",
    "\n",
    "# Drop rows with extreme outliers\n",
    "survey_data = survey_data.drop(survey_data[survey_data['ConvertedCompYearly'] > 400000].index)\n",
    "\n",
    "# Check if the numbers look reasonable\n",
    "survey_data[['ConvertedCompYearly']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Clean more columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['YearsCode', 'YearsCodePro']\n",
    "\n",
    "for col_name in numeric_features:\n",
    "    survey_data[col_name] = pd.to_numeric(survey_data[col_name], errors='coerce')\n",
    "    survey_data = survey_data.dropna(subset = [col_name])  \n",
    "\n",
    "survey_data[numeric_features].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Map a column to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_data['EdLevelNumeric'] = survey_data['EdLevel'].map({\n",
    "    'Professional degree (JD, MD, etc.)': 24,\n",
    "    'Other doctoral degree (Ph.D., Ed.D., etc.)': 22,\n",
    "    'Master’s degree (M.A., M.S., M.Eng., MBA, etc.)': 18,\n",
    "    'Bachelor’s degree (B.A., B.S., B.Eng., etc.)': 16,\n",
    "    'Associate degree (A.A., A.S., etc.)': 14,\n",
    "    'Some college/university study without earning a degree': 13,\n",
    "    'Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)': 12,\n",
    "    'Primary/elementary school': 6,\n",
    "    'Something else': 0,\n",
    "})\n",
    "survey_data = survey_data.dropna(subset = [\"EdLevelNumeric\"])\n",
    "numeric_features.append('EdLevelNumeric')\n",
    "survey_data[[\"EdLevelNumeric\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualize the label column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "label = survey_data['ConvertedCompYearly']\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "ax = fig.gca()\n",
    "ax.hist(label, bins=100)\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.axvline(label.mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
    "ax.axvline(label.median(), color='cyan', linestyle='dashed', linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualize the feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col_name in numeric_features:\n",
    "    fig = plt.figure(figsize=(6, 4))  # TODO: subplot\n",
    "    ax = fig.gca()\n",
    "    feature = survey_data[col_name]\n",
    "    feature.hist(bins=100, ax = ax)\n",
    "    ax.axvline(feature.mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
    "    ax.axvline(feature.median(), color='cyan', linestyle='dashed', linewidth=2)\n",
    "    ax.set_title(col_name)\n",
    "# todo: a cell above it thats ignored that has all the matplotlib config code and is called from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a bar plot for each categorical feature count\n",
    "categorical_features = ['Age','Gender','Trans', 'EdLevel']\n",
    "\n",
    "for col in categorical_features:\n",
    "    counts = survey_data[col].value_counts().sort_index()\n",
    "    fig = plt.figure(figsize=(9, 6))\n",
    "    ax = fig.gca()\n",
    "    counts.plot.bar(ax = ax, color='steelblue')\n",
    "    ax.set_title(col + ' counts')\n",
    "    ax.set_xlabel(col) \n",
    "    ax.set_ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Measure correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numeric_features:\n",
    "    fig = plt.figure(figsize=(9, 6))\n",
    "    ax = fig.gca()\n",
    "    feature = survey_data[col]\n",
    "    label = survey_data['ConvertedCompYearly']\n",
    "    correlation = feature.corr(label)\n",
    "    plt.scatter(x=feature, y=label)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Yearly Comp')\n",
    "    ax.set_title('comp vs ' + col + '- correlation: ' + str(correlation))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Build a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Separate test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "X, y = survey_data[['YearsCode','YearsCodePro', 'EdLevelNumeric']].values, survey_data['ConvertedCompYearly'].values\n",
    "print('Features:', X[:10], '\\nLabels:', y[:10], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# TODO: scikit learn just got a pandas integration, so its easy to pass dfs back and forth\n",
    "\n",
    "# Split data 70%-30% into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "print ('Training Set: %d rows\\nTest Set: %d rows' % (X_train.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression().fit(X_train, y_train)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluate model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "np.set_printoptions(suppress=True)\n",
    "print('Predicted labels: ', np.round(predictions)[:10])\n",
    "print('Actual labels   : ', y_test[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualize the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, predictions)\n",
    "plt.xlabel('Actual Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.title('Yearly Comp Predictions')\n",
    "# Overlay the regression line\n",
    "z = np.polyfit(y_test, predictions, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(y_test,p(y_test), color='magenta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Calculate evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"MSE:\", mse)\n",
    "\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"R2:\", r2) # TODO: be able to explain better. residuals squared. higher is better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Experiment with more models\n",
    "\n",
    "* **Linear algorithms**: Not just the Linear Regression algorithm we used above (which is technically an Ordinary Least Squares algorithm), but other variants such as Lasso and Ridge.\n",
    "* **Tree-based algorithms**: Algorithms that build a decision tree to reach a prediction.\n",
    "* **Ensemble algorithms**: Algorithms that combine the outputs of multiple base algorithms to improve generalizability.\n",
    "\n",
    "https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generalize the evaluation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model():\n",
    "    # Evaluate the model using the test data\n",
    "    predictions = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    print(\"MSE:\", mse, \" RMSE:\", rmse, \" R2:\", r2, )\n",
    "\n",
    "    # Plot predicted vs actual\n",
    "    plt.scatter(y_test, predictions)\n",
    "    plt.xlabel('Actual Labels')\n",
    "    plt.ylabel('Predicted Labels')\n",
    "    plt.title('Yearly Comp Predictions')\n",
    "    # Overlay the regression line\n",
    "    z = np.polyfit(y_test, predictions, 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(y_test,p(y_test), color='magenta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lasso (linear regression)\n",
    "\n",
    "Lasso works well when only a few features predict the label.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/linear_model.html#lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Fit a lasso model on the training set\n",
    "model = Lasso().fit(X_train, y_train)\n",
    "\n",
    "evaluate_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Decision tree\n",
    "\n",
    "Decision trees can be used for both regression and classification problems.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/tree.html#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_text\n",
    "\n",
    "model = DecisionTreeRegressor().fit(X_train, y_train)\n",
    "\n",
    "# Visualize the model tree\n",
    "tree = export_text(model)\n",
    "print(tree)\n",
    "# TODO: graphviz trees: https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Decision tree (evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Random forest (ensemble)\n",
    "\n",
    "Applies an averaging function to multiple Decision Tree models for a better overall model\n",
    "https://scikit-learn.org/stable/modules/ensemble.html#forests-of-randomized-trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor().fit(X_train, y_train)\n",
    "\n",
    "evaluate_model() # TODO: Add to a pandas dataframe to show our progress so far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gradient tree boosting\n",
    "\n",
    "https://scikit-learn.org/stable/modules/ensemble.html#gradient-tree-boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "model = GradientBoostingRegressor().fit(X_train, y_train)\n",
    "\n",
    "evaluate_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Improve model\n",
    "\n",
    "* Tune hyperparameters\n",
    "* Preprocess data\n",
    "\n",
    "https://learn.microsoft.com/en-us/training/modules/train-evaluate-regression-models/6-improve-models\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "\n",
    "# Use a Gradient Boosting algorithm\n",
    "alg = GradientBoostingRegressor()\n",
    "\n",
    "# Try these hyperparameter values\n",
    "params = {\n",
    " 'learning_rate': [0.1, 0.5, 1.0],\n",
    " 'n_estimators' : [50, 100, 150]\n",
    " }\n",
    "\n",
    "# Find the best hyperparameter combination to optimize the R2 metric\n",
    "score = make_scorer(r2_score)\n",
    "gridsearch = GridSearchCV(alg, params, scoring=score, cv=3, return_train_score=True)\n",
    "gridsearch.fit(X_train, y_train)\n",
    "print(\"Best parameter combination:\", gridsearch.best_params_, \"\\n\")\n",
    "\n",
    "# Get the best model\n",
    "model = gridsearch.best_estimator_ # TODO but why\n",
    "print(model, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluate tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pre-processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = survey_data[['YearsCode','YearsCodePro', 'EdLevel', 'MainBranch', 'Country']].values, survey_data['ConvertedCompYearly'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Define preprocessing for numeric columns (scale them)\n",
    "numeric_features = [0, 1]\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# Define preprocessing for categorical features (encode them)\n",
    "categorical_features = [2, 3, 4]\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Create preprocessing and training pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('regressor', model)])\n",
    "\n",
    "# fit the pipeline to train a linear regression model on the training set\n",
    "model = pipeline.fit(X_train, (y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluate tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model() # TODO: why the cap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Store the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model as a pickle file\n",
    "filename = './function/yearly-comp.pkl'\n",
    "joblib.dump(model, filename)\n",
    "\n",
    "# TODO hdf5 - compression format - what is most performant for pickling/depickling?\n",
    "# cafe and tf files are other types of model files\n",
    "# or pickle? onyx\n",
    "# TODO: read scikit learn's page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Use the stored model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from the file\n",
    "loaded_model = joblib.load(filename)\n",
    "\n",
    "# Create a numpy array containing a new observation (for example tomorrow's seasonal and weather forecast information)\n",
    "X_new = np.array([[25, 15, 'Master’s degree (M.A., M.S., M.Eng., MBA, etc.)','I am a developer by profession', ' ']])\n",
    "#X_new = np.array([[8, 6, 'Bachelor’s degree (B.A., B.S., B.Eng., etc.)','I am a developer by profession', 'United States of America']])\n",
    "print ('New sample: {}'.format(list(X_new[0])))\n",
    "\n",
    "# Use the model to predict tomorrow's rentals\n",
    "result = loaded_model.predict(X_new)\n",
    "print('Prediction: ${:.0f}'.format(np.round(result[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "uniques = []\n",
    "for country in survey_data['Country'].unique():\n",
    "    var_name = country.replace(' ', '_').upper() # todo: slugify\n",
    "    #print(var_name + ' = \"' + country + '\"')\n",
    "\n",
    "survey_data['MainBranch'].unique()\n",
    "# TODO: generate enums.py and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "rise": {
   "center": false,
   "theme": "simple",
   "transition": "none"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
